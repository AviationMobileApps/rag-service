# rag-service (local dev on macOS)

# API
RAG_API_PORT=8021

# Postgres
POSTGRES_USER=rag
POSTGRES_PASSWORD=rag
POSTGRES_DB=rag
POSTGRES_PORT=5433

# Redis
REDIS_PORT=6380

# Weaviate
WEAVIATE_HTTP_PORT=8081
WEAVIATE_GRPC_PORT=50052

# Neo4j
NEO4J_PASSWORD=rag-service
NEO4J_HTTP_PORT=7475
NEO4J_BOLT_PORT=7688

# Storage (bind-mounted into rag-api + rag-worker)
RAG_DATA_DIR=/data

# Multi-tenant API keys (Bearer tokens)
# JSON array: [{ "tenant_id": "...", "api_key": "..." }]
RAG_TENANTS_JSON=[{"tenant_id":"signal305","api_key":"dev-signal305-key"},{"tenant_id":"newproj","api_key":"dev-newproj-key"}]

# Embeddings (LM Studio on the host Mac)
EMBEDDINGS_BASE_URL=http://host.docker.internal:1234
EMBEDDINGS_MODEL=text-embedding-nomic-embed-text-v1.5-embedding
EMBEDDINGS_API_KEY=

# LLM for chunking/entity extraction/schema discovery (LM Studio on the host Mac)
LLM_BASE_URL=http://host.docker.internal:1234
LLM_MODEL=gpt-oss-120b
LLM_API_KEY=
LLM_TIMEOUT_S=300

# Reranker (cross-encoder; downloads weights on first boot into MODEL_CACHE_DIR)
RERANKER_ENABLED=1
RERANKER_MODEL=BAAI/bge-reranker-base
RERANK_OVERSAMPLE=3

# Chunking (LLM-driven dynamic chunking; falls back to fixed-size if LLM fails)
DYNAMIC_CHUNKING_ENABLED=1
CHUNKER_WINDOW_TOKENS=16000
CHUNKER_OVERLAP_TOKENS=1000
CHUNKER_LLM_MAX_TOKENS=20000
CHUNKER_TOKENIZER_MODEL=cl100k_base

# Entities + graph
ENTITY_EXTRACTION_MAX_ENTITIES=25
GRAPH_ENABLED=1
GRAPH_EXPANSION_ENABLED=1
GRAPH_SEED_LIMIT=8
GRAPH_SEED_MIN_RERANK_SCORE=0.2
GRAPH_EXPANSION_LIMIT=20
GRAPH_ENTITY_LIMIT=25
